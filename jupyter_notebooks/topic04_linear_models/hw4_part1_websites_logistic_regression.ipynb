{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "</center>\n",
    "<center>Автор материала: Юрий Исаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <center> Домашнее задание № 4. Часть 1\n",
    "## <center>  Идентификация пользователя с помощью логистической регрессии\n",
    "\n",
    "В этой домашней работе мы научимся работать с разреженными матрицами, обучать логистическую регрессию, формировать и отбирать признаки, а также воспроизведем два бейслайна учебного [соревнования](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking) \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\" на Kaggle Inclass. В этой домашней работе 9 заданий, которые вам предстоит выполнить и после этого заполнить ответы в [гугл-форме](https://docs.google.com/forms/d/e/1FAIpQLSd8E7naU38ikc9-rd31KeVfez3emCo4Ok1WrpQTr-XCDelRiw/viewform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# загрузим библиотеки и установим опции\n",
    "\n",
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### О соревновании\n",
    "Мы будем решать задачу идентификации взломщика по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера: компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в статье на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\".\n",
    "\n",
    "В этом соревновании будем решать похожую задачу: алгоритм будет анализировать последовательность из нескольких веб-сайтов, посещенных подряд одним и тем же человеком, и определять, Элис это или взломщик (кто-то другой). В качестве метрики в этом соревновании используется [ROC AUC](https://ru.wikipedia.org/wiki/ROC-кривая). Кто такая Элис, мы расскажем в конце курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Загрузка и преобразование данных\n",
    "Зарегистрируйтесь на [Kaggle](www.kaggle.com), если вы не сделали этого раньше, зайдите на [страницу](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking) соревнования и скачайте данные. Первым делом загрузим обучающую и тестовую выборки, посмотрим на данные и выполним несколько простых заданий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('../../data/websites_train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('../../data/websites_test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В обучающей выборке содержатся следующие признаки:\n",
    "    - site1 – индекс первого посещенного сайта в сессии\n",
    "    - time1 – время посещения первого сайта в сессии\n",
    "    - ...\n",
    "    - site10 – индекс 10-го посещенного сайта в сессии\n",
    "    - time10 – время посещения 10-го сайта в сессии\n",
    "    - target – целевая переменная, принимает значение 1 для сессий Элис и 0 для сессий других пользователей\n",
    "    \n",
    "Сессии пользователей выделены таким образом, что они не могут быть длинее получаса или содержит более 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд, либо когда сессия заняла по времени более 30 минут.\n",
    "\n",
    "В таблице встречаются пропущенные значения, это значит, что сессия состоит менее, чем из 10 сайтов. Заменим пропущенные значения нулем и приведем колонки целому типу. Также загрузим словарь сайтов и посмотрим как он выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14710</th>\n",
       "      <td>erwy.developpez.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20382</th>\n",
       "      <td>www.laboutiquescienceetvie.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>coverage.osm.mapquest.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28083</th>\n",
       "      <td>www.1euro.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37439</th>\n",
       "      <td>dinochat.ze-forum.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 site\n",
       "14710             erwy.developpez.com\n",
       "20382  www.laboutiquescienceetvie.com\n",
       "5057        coverage.osm.mapquest.com\n",
       "28083                   www.1euro.com\n",
       "37439           dinochat.ze-forum.com"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "#### Задание 1: Какие размерности имеют тестовая и обучающая выборки?\n",
    "\n",
    "- (82797, 20) (253561, 20)\n",
    "- (82797, 20) (253561, 21)\n",
    "- (253561, 21) (82797, 20)\n",
    "- (253561, 20) (82797, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовая выборка:  (82797, 20)\n",
      "Обучающая выборка:  (253561, 21)\n"
     ]
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "print('Тестовая выборка: ', test_df.shape)\n",
    "print('Обучающая выборка: ', train_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Очень краткий первичный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Перед тем, как начинать строить модели, необходимо провести первичный (разведочный) анализ ([EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis)). Мы сделаем его краткую версию, но по мере продвижения начнём пользоваться другими его техниками. Посмотрим, какие сайты из обучающей выборки наиболее посещаемые. Ими оказались сервисы компании Гугл и сайт по биоинформатике (сайт с \"нулевым\" индексом — это наши пропущенные значения, просто проигнорируем его):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21     123776\n",
      "0      122730\n",
      "23      87619\n",
      "782     77055\n",
      "22      58258\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>annotathon.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>apis.google.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                site\n",
       "21     www.google.fr\n",
       "0                NaN\n",
       "23    www.google.com\n",
       "782   annotathon.org\n",
       "22   apis.google.com"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# топ-сайты в обучающей выборке\n",
    "top_sites = pd.Series(train_df[sites].fillna(0).values.flatten()\n",
    "                     ).value_counts().sort_values(ascending=False).head(5)\n",
    "print(top_sites)\n",
    "sites_dict.ix[top_sites.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Задание 2: Какие сайты Элис посещает в сети наиболее часто?\n",
    "\n",
    "- видеохостинги\n",
    "- социальные сети\n",
    "- торрент-трекеры\n",
    "- новостные сайты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77    1382\n",
      "80    1354\n",
      "76    1307\n",
      "29     897\n",
      "21     857\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>i1.ytimg.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>s.youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>www.youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>www.facebook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>www.google.fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                site\n",
       "77      i1.ytimg.com\n",
       "80     s.youtube.com\n",
       "76   www.youtube.com\n",
       "29  www.facebook.com\n",
       "21     www.google.fr"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "top_alice_sites = pd.Series(train_df[train_df[\"target\"] == 1][sites].fillna(0).values.flatten()\n",
    "                     ).value_counts().sort_values(ascending=False).head(5)\n",
    "print(top_alice_sites)\n",
    "sites_dict.ix[top_alice_sites.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Теперь посмотрим на временные отметки и попробуем охарактеризовать сессии временными интервалами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>1786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                 min                 max  seconds\n",
       "session_id                                                         \n",
       "21669            0 2013-01-12 08:05:57 2013-01-12 08:05:57      0.0\n",
       "54843            0 2013-01-12 08:37:23 2013-01-12 09:07:09   1786.0\n",
       "77292            0 2013-01-12 08:50:13 2013-01-12 08:50:17      4.0\n",
       "114021           0 2013-01-12 08:50:17 2013-01-12 08:50:20      3.0\n",
       "146670           0 2013-01-12 08:50:20 2013-01-12 08:50:22      2.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим отдельный датафрейм, где будем работать со временем\n",
    "time_df = pd.DataFrame(index=train_df.index)\n",
    "time_df['target'] = train_df['target']\n",
    "\n",
    "# найдем время начала и окончания сессии\n",
    "time_df['min'] = train_df[times].min(axis=1)\n",
    "time_df['max'] = train_df[times].max(axis=1)\n",
    "\n",
    "# вычислим длительность сессии и переведем в секунды\n",
    "time_df['seconds'] = (time_df['max'] - time_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Чтобы выполнить следующее задание, составьте описательные статистики по образу тех, которые вы делали в домашней работе на первой неделе. \n",
    "\n",
    "##### Задание 3. Выберите все верные утверждения (может оказаться один верный ответ, несколько или ни одного):\n",
    "\n",
    "- в среднем сессия Элис короче, чем у остальных пользователей\n",
    "- доля сессий Элис в выборке больше 1%\n",
    "- диапазоны длительности сессий и Элис, и остальных примерно одинаковы\n",
    "- разброс значений относительно среднего у всех пользователей (Элис в том числе) приблизительно одинаков\n",
    "- доля сессий Элис от 40 секунд и дольше составляет менее четверти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.2964736613\n",
      "139.282372326\n",
      "138.494370191\n",
      "\n",
      "2297\n",
      "251264\n",
      "\n",
      "153.309014053\n",
      "296.653517719\n",
      "1743\n",
      "109122\n"
     ]
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "print(time_df[time_df['target'] == 1][\"seconds\"].mean())\n",
    "print(time_df[time_df['target'] == 0][\"seconds\"].mean())\n",
    "print(time_df[\"seconds\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "print(time_df[time_df['target'] == 1][\"seconds\"].count())\n",
    "print(time_df[time_df['target'] == 0][\"seconds\"].count())\n",
    "\n",
    "print()\n",
    "\n",
    "print(time_df[time_df['target'] == 1][\"seconds\"].std())\n",
    "print(time_df[time_df['target'] == 0][\"seconds\"].std())\n",
    "\n",
    "print(time_df[(time_df['target'] == 1) & (time_df[\"seconds\"] < 40)][\"seconds\"].count())\n",
    "print(time_df[(time_df['target'] == 0) & (time_df[\"seconds\"] >= 40)][\"seconds\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Чтобы обучить нашу первую модель, необходимо подготовить данные. С самого начала выделим целевую переменную и удалим ее из обучающей выборки. Теперь и обучающая, и тестовая выборки будут иметь одинаковое количество колонок, поэтому объединим их в один общий датафрейм. Таким образом, все преобразования будут выполняться одновременно как для обучающей, так и для тестовой выборок. С одной стороны, это ведет к тому, что у обеих выборок будет одно пространство признаков (можно не волноваться, что забыли сделать преобразование какого-то признака для одной из выборок), но с другой возрастает время обработки. Для больших выборок может оказаться невозможным сделать преобразования одновременно для обеих выборок (а иногда преобразования придется разбивать на несколько этапов только для обучающей/тестовой выборки). Здесь же мы будем делать преобразования для объединенной таблицы целиком, а перед обучением или прогнозированием просто возьмем нужную ее часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для самой первой модели будем использовать только посещенные сайты в сессии (но не будем обращать внимание на временные признаки). За таким выбором данных для модели стоит следующая идея:  *у Элис есть свои излюбленные сайты, и чем чаще вы видим эти сайты в сессии, тем выше вероятность, что это сессия Элис, и наоборот.*\n",
    "\n",
    "Подготовим данные, из всей таблицы выберем только признаки `site1, site2, ... , site10`. Напомним, что пропущенные значения заменены нулем. Вот как выглядят первые строки таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Сессии представляют собой последовательность индексов сайтов, и данные в таком виде неудобны для линейных методов. В соответствии с нашей гипотезой (у Элис есть излюбленные сайты) надо преобразовать эту таблицу таким образом, чтобы каждому возможному сайту соответствовал свой отдельный признак (колонка), а его значение равнялось бы количеству посещений этого сайта в сессии. Это делается в две строчки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Если вы поняли, что здесь произошло, то можете пропустить следующий кусок (может, и с логистической регрессией тоже умеете обращаться?), если нет, то давайте разберемся.\n",
    "\n",
    "### Лирическое отступление 1: разреженные матрицы\n",
    "\n",
    "Оценим, сколько потребуется памяти для хранения наших данных на примере преобразований выше. Наша объединенная таблица содержит 336 тысяч наблюдений по 48 тысяч целочисленных признаков в каждом. Нетрудно посчитать необходимый объем памяти, навскидку это: $$336K * 48K * 8 байт = 16M * 8 байт = 128 Гбайт,$$ (а вот [точное](http://www.wolframalpha.com/input/?i=336358*48371*8+bytes) значение). Очевидно, что таких объемов у простых смертных нет (вообще говоря, Питон может и позволить вам создать такую матрицу, но вот уже что-то сделать с ней будет непросто). Что характерно, большинство элементов нашей матрицы — нули. Если мы посчитаем ненулевые элементы, то их окажется порядка 1.8 млн., т.е. чуть больше 10% от всех элементов матрицы. Такая матрица, где большинство элементов нулевые, называется разреженной, а отношение количества нулевых элементов к общему числу элементов называется разреженностью матрицы.\n",
    "\n",
    "Для работы с такими данными можно использовать библиотеку `scipy.sparse`, посмотрите [документацию](https://docs.scipy.org/doc/scipy-0.18.1/reference/sparse.html), чтобы разобраться, какие разреженные матрицы бывают, как с ними работать и в каких случаях их использование наиболее эффективно. О том, как они устроены, можно прочитать, например, в [статье](https://en.wikipedia.org/wiki/Sparse_matrix) англоязычной Википедии. Мы же отметим, что разреженная матрица хранит только ненулевые элементы, а место, занимаемое в памяти можно получить вот так (очевидна существенная экономия памяти):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1866898 elements * 8 bytes = 14935184 bytes\n",
      "sparse_matrix_size = 7467592 bytes\n"
     ]
    }
   ],
   "source": [
    "# Сколько места занимает разреженная матрица в памяти?\n",
    "print('{0} elements * {1} bytes = {2} bytes'.format(full_sites_sparse.count_nonzero(), 8, \n",
    "                                                    full_sites_sparse.count_nonzero() * 8))\n",
    "# или сразу вот так:\n",
    "print('sparse_matrix_size = {0} bytes'.format(full_sites_sparse.data.nbytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Давайте теперь на минипримере разберемся, как была сформирована матрица с сайтами. Предположим, у нас имеется вот такая таблица с сессиями пользователей:\n",
    "\n",
    "| id | site1 | site2 | site3 |\n",
    "|---|---|---|---|\n",
    "| 1 | 1 | 0 | 0 |\n",
    "| 2 | 1 | 3 | 1 |\n",
    "| 3 | 2 | 3 | 4 |\n",
    "\n",
    "Имеется 3 сессии, в каждой из них не более 3 сайтов. Пользователи посещали четыре различных сайта (в ячейках таблицы числа от 1 до 4). Пусть  для определенности:\n",
    "\n",
    " 1. vk.com\n",
    " 2. habrahabr.ru \n",
    " 3. yandex.ru\n",
    " 4. ods.ai\n",
    "\n",
    "Если за сессию пользователь посетил меньше сайтов, то последние несколько значений будут ноликами. Мы хотим преобразовать исходные данные таким образом, чтобы каждой сессии соответствовала строка, которая отображала, сколько было посещений каждого конкретного сайта. Т.е. предыдущую таблицу мы хотим представить в виде:\n",
    "\n",
    "| id | vk.com | habrahabr.ru | yandex.ru | ods.ai |\n",
    "|---|---|---|---|---|\n",
    "| 1 | 1 | 0 | 0 | 0 |\n",
    "| 2 | 2 | 0 | 1 | 0 |\n",
    "| 3 | 0 | 1 | 1 | 1 |\n",
    "\n",
    "Для этого воспользуемся конструктором: `csr_matrix((data, indices, indptr))` и составим частотную таблицу (посмотрите примеры, код и комментарии по ссылкам выше, чтобы понять как это работает). Здесь для большей понятности все параметры зададим вручную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2, 1, 0, 0, 0],\n",
       "        [0, 2, 0, 1, 0],\n",
       "        [0, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# данные, создаем список единичек, длина которого равна количеству элементов в исходной таблице (9)\n",
    "# просуммировав количество единичек в ячейке получим частоту, \n",
    "# сколько было посещений определенного сайта за сессию\n",
    "data = [1] * 9\n",
    "\n",
    "# для этого надо правильно распределить единички по ячейкам\n",
    "# индексы - номера сайтов, по ним будут суммироваться единички за сессии, т.е. колонки новой матрицы\n",
    "indices = [1, 0, 0, 1, 3, 1, 2, 3, 4]\n",
    "\n",
    "# индексы разбиения на строки (сессии)\n",
    "# например, строка 0 это элементы между индексами [0; 3) - крайнее правое значение не включается\n",
    "# строка 1 это элементы между индексами [3; 6) \n",
    "# строка 2 это элементы между индексами [6; 9) \n",
    "indptr = [0, 3, 6, 9]\n",
    "\n",
    "# объединим эти три переменных в кортеж и сформируем матрицу\n",
    "# чтобы вывести на экран преобразуем в обычную \"плотную\" матрицу\n",
    "csr_matrix((data, indices, indptr)).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Как вы могли заметить, в получившейся матрице не 4 столбца (по количеству различных сайтов), а 5. Добавился нулевой столбец, который сообщает, на сколько единиц сессия оказалась короче (в нашем минипримере мы брали сессии длины 3). Этот столбец лишний и его надо убрать из рассмотрения (сделайте это сами). \n",
    "\n",
    "##### Задание 4: А теперь еще один вопрос, чему равна разреженность матрицы из минипримера?\n",
    "\n",
    "- 42%\n",
    "- 47%\n",
    "- 50%\n",
    "- 53%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "6/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Еще один плюс использования разреженных матриц в том, что для них имеются специальные реализации как матричных операций, так и алгоритмов машинного обучения, что подчас позволяет ощутимо ускорить операции за счет особенностей структуры данных. Это касается и логистической регрессии. Вот теперь у нас все готово для построения нашей первой модели.\n",
    "\n",
    "### 3. Построение первой модели\n",
    "\n",
    "Итак, у нас есть алгоритм и данные для него, построим нашу первую модель, воспользовавшись реализацией [логистической регрессии](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из пакета `sklearn` с параметрами по умолчанию. Первые 90% данных будем использовать для обучения (обучающая выборка отсортирована по времени), а оставшиеся 10% для проверки качества (validation). Напишем простую функцию, которая будет возвращать качество модели и обучим наш первый классификатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, seed=17, ratio = 0.9):\n",
    "    # разделим выборку на обучающую и валидационную\n",
    "    idx = int(round(X.shape[0] * ratio))\n",
    "    # обучение классификатора\n",
    "    lr = LogisticRegression(C=C, random_state=seed, n_jobs=-1).fit(X[:idx, :], y[:idx])\n",
    "    # прогноз для валидационной выборки\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # считаем качество\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919524256796\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# выделим из объединенной выборки только обучающую (для которой есть ответы)\n",
    "X_train = full_sites_sparse[:idx_split, :]\n",
    "\n",
    "# считаем метрику на валидационной выборке\n",
    "print(get_auc_lr_valid(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Первая модель показала качество 0.91952 на отложенной выборке. Будем считать эту модель нашим первым бейслайном, отправной точкой. Для построения модели для прогноза на тестовой выборке **необходимо обучить модель заново уже на всей обучающей выборке** (пока наша модель обучалась лишь на части данных), что повысит ее обобщающую способность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# обучим модель на всей выборке\n",
    "# random_state=17 для воспроизводимости\n",
    "# параметр C=1 по умолчанию, но здесь мы его укажем явно\n",
    "lr = LogisticRegression(C=1.0, random_state=17).fit(X_train, y_train)\n",
    "\n",
    "# сделаем прогноз для тестовой выборки\n",
    "X_test = full_sites_sparse[idx_split:,:]\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# запишем его в файл, готовый для сабмита\n",
    "write_to_submission_file(y_test, 'baseline_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Если вы выполните эти действия и загрузите ответ на [странице](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking) соревнования, то получите качество `ROC AUC = 0.91707` на публичном лидерборде.\n",
    "\n",
    "### 4. Улучшение модели, построение новых признаков\n",
    "\n",
    "Попробуем улучшить качество, добавив новые признаки в модель. Но сначала ответим на вопрос:\n",
    "\n",
    "##### Задание 5: данные за какие годы представлены в обучающей и тестовой выборке?\n",
    "\n",
    "- за 13 и 14\n",
    "- за 2012 и 2013\n",
    "- за 2013 и 2014\n",
    "- за 2014 и 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82797</td>\n",
       "      <td>81308</td>\n",
       "      <td>80075</td>\n",
       "      <td>79182</td>\n",
       "      <td>78341</td>\n",
       "      <td>77566</td>\n",
       "      <td>76840</td>\n",
       "      <td>76151</td>\n",
       "      <td>75484</td>\n",
       "      <td>74806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>77269</td>\n",
       "      <td>75845</td>\n",
       "      <td>74786</td>\n",
       "      <td>73967</td>\n",
       "      <td>73130</td>\n",
       "      <td>72451</td>\n",
       "      <td>71864</td>\n",
       "      <td>71233</td>\n",
       "      <td>70576</td>\n",
       "      <td>69833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "      <td>2014-05-27 11:36:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2014-05-01 17:14:03</td>\n",
       "      <td>2014-05-02 07:54:08</td>\n",
       "      <td>2014-05-02 07:54:08</td>\n",
       "      <td>2014-05-02 07:55:09</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>2014-05-02 08:05:17</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "      <td>2014-05-02 08:05:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2014-12-05 23:26:53</td>\n",
       "      <td>2014-12-05 23:26:53</td>\n",
       "      <td>2014-12-05 23:56:23</td>\n",
       "      <td>2014-12-05 23:56:23</td>\n",
       "      <td>2014-12-05 20:24:08</td>\n",
       "      <td>2014-12-05 19:10:09</td>\n",
       "      <td>2014-12-05 19:10:03</td>\n",
       "      <td>2014-12-05 19:10:03</td>\n",
       "      <td>2014-12-05 19:10:03</td>\n",
       "      <td>2014-12-05 19:10:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time1                time2                time3  \\\n",
       "count                 82797                81308                80075   \n",
       "unique                77269                75845                74786   \n",
       "top     2014-05-27 11:36:54  2014-05-27 11:36:54  2014-05-27 11:36:54   \n",
       "freq                      7                    7                    8   \n",
       "first   2014-05-01 17:14:03  2014-05-02 07:54:08  2014-05-02 07:54:08   \n",
       "last    2014-12-05 23:26:53  2014-12-05 23:26:53  2014-12-05 23:56:23   \n",
       "\n",
       "                      time4                time5                time6  \\\n",
       "count                 79182                78341                77566   \n",
       "unique                73967                73130                72451   \n",
       "top     2014-05-27 11:36:54  2014-05-27 11:36:54  2014-05-27 11:36:54   \n",
       "freq                      9                    7                    7   \n",
       "first   2014-05-02 07:55:09  2014-05-02 08:05:17  2014-05-02 08:05:17   \n",
       "last    2014-12-05 23:56:23  2014-12-05 20:24:08  2014-12-05 19:10:09   \n",
       "\n",
       "                      time7                time8                time9  \\\n",
       "count                 76840                76151                75484   \n",
       "unique                71864                71233                70576   \n",
       "top     2014-05-27 11:36:54  2014-05-27 11:36:54  2014-05-27 11:36:54   \n",
       "freq                      7                    7                    7   \n",
       "first   2014-05-02 08:05:18  2014-05-02 08:05:18  2014-05-02 08:05:18   \n",
       "last    2014-12-05 19:10:03  2014-12-05 19:10:03  2014-12-05 19:10:03   \n",
       "\n",
       "                     time10  \n",
       "count                 74806  \n",
       "unique                69833  \n",
       "top     2014-05-27 11:36:54  \n",
       "freq                      7  \n",
       "first   2014-05-02 08:05:18  \n",
       "last    2014-12-05 19:10:03  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код\n",
    "test_df[times].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Создадим такой признак, который будет представлять из себя число вида ГГГГММ от той даты, когда проходила сессия, например 201407 -- 2014 год и 7 месяц. Таким образом мы будем учитывать помесячный [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь период предоставленных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# датафрейм для новых признаков\n",
    "full_new_feat = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "# добавим признак start_month\n",
    "full_new_feat['start_month'] = full_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Задание 6: Постройте график количества сессий Элис в зависимости от новой переменной start_month. Выберите верное утверждение:\n",
    "\n",
    "- Элис вообще не выходила в сеть за все это время\n",
    "- с начала 2013 года по середину 2014 года количество ежемесячных сессий уменьшилось\n",
    "- в целом количество сессий Элис за месяц постоянно на протяжении всего периода\n",
    "- с начала 2013 года по середину 2014 года количество ежемесячных сессий возросло\n",
    "\n",
    "*Подсказка: график будет нагляднее, если трактовать `start_month` как категориальную порядковую переменную*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28238f9f780>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEeCAYAAACaDO5vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE15JREFUeJzt3X2QXXV9x/H3JgtiaMCAa4uj1HEYvrXTqgNO8QFIRJAi\ntSlqKyLIQ/GhjQ+MOBoVJI46pYpMH8SBghjLaEdFwco0GhWGxkhhdHyANn6tnVqkFQ00SDAqJNn+\ncc7WZbMPN5uzOb/7y/s1k+Hsufee++HuvZ/7298959yR8fFxJEnDb1HfASRJ3bDQJakSFrokVcJC\nl6RKWOiSVAkLXZIqMdrnnW/evLWTfSaXLVvCli3buthUp0rMZabBmGlwJeaqPdPY2NKR6dZXMUIf\nHV3cd4RplZjLTIMx0+BKzLWvZqqi0CVJFrokVcNCl6RKWOiSVAkLXZIqYaFLUiUsdEmqhIUuSZXo\n9UhR1e+8S2/uZDvXrj6hk+1INXOELkmVsNAlqRIWuiRVwkKXpEpY6JJUCQtdkiphoUtSJSx0SaqE\nhS5JlbDQJakSFrokVcJCl6RKWOiSVAkLXZIqYaFLUiUsdEmqhF9wIWlaXX05CfgFJXvLQIUeEU8A\nvgGcBGwH1gLjwF3AqszcGRGXAKe2l1+QmXcsSGJJ0rTmnHKJiP2Aq4Cft6suBy7KzOOAEWBlRBwF\nLAeOAU4HrliYuJKkmQwyh34ZcCXwP+3PRwO3tsvrgBOBY4H1mTmemXcDoxEx1nVYSdLMZp1yiYhz\ngM2Z+cWIeHu7eiQzx9vlrcDBwEHA/ZNuOrF+82zbX7ZsCaOji+eTexdjY0s72U7XSsxVYqa59JG5\nxMepxEyD6DL3iy/8XCfb+fwHV3aynd2x0L+/uebQzwPGI+JE4JnA3wNPmHT5UuAB4MF2eer6WW3Z\nsm23ws5kbGwpmzdv7WRbXSoxV4mZBrG3M5f4OJWYaVAl5h7m59RMbwyzTrlk5vGZuTwzVwDfAl4F\nrIuIFe1VTgE2ABuBkyNiUUQcDizKzPs6SS5JGsh8dlu8ELg6IvYHNgHXZ+aOiNgA3EbzJrGqw4yS\npAEMXOjtKH3C8mkuXwOs2eNEkqR58UhRSaqEhS5JlbDQJakSFrokVcJCl6RKWOiSVAlPn1uRrk53\n6qlOpeHkCF2SKmGhS1IlLHRJqoSFLkmVsNAlqRIWuiRVwkKXpEpY6JJUCQtdkiphoUtSJSx0SaqE\nhS5JlbDQJakSFrokVcJCl6RKWOiSVAkLXZIqYaFLUiUsdEmqhIUuSZWw0CWpEha6JFXCQpekSljo\nklQJC12SKmGhS1IlLHRJqoSFLkmVsNAlqRIWuiRVwkKXpEpY6JJUidG5rhARi4GrgQB2AOcCI8Ba\nYBy4C1iVmTsj4hLgVGA7cEFm3rFAuSVJUwwyQn8xQGY+D3gXcHn776LMPI6m3FdGxFHAcuAY4HTg\nigVJLEma1pwj9My8MSJuan/8TeDHNKPwW9t164AXAgmsz8xx4O6IGI2IsczcvAC5JakY5116cyfb\nuXb1CXt0+zkLHSAzt0fEx4DTgJcBf9AWN8BW4GDgIOD+STebWD9joS9btoTR0cXzyb2LsbGlnWyn\na6Xmmk2JmfvI5OPQnRJz15hpoEIHyMyzI+JtwO3AYyddtBR4AHiwXZ66fkZbtmwbPOksxsaWsnnz\n1k621aVSc82lxMx7O1OJv7sSMw2qxNzDnGmm4p9zDj0izoqIt7c/bgN2Al+PiBXtulOADcBG4OSI\nWBQRhwOLMvO+gdJJkvbYICP0zwIfjYh/BvYDLgA2AVdHxP7t8vWZuSMiNgC30bxRrFqgzJKkaQzy\noejPgD+Z5qLl01x3DbBmj1NJknabBxZJUiUsdEmqhIUuSZWw0CWpEha6JFXCQpekSljoklQJC12S\nKmGhS1IlLHRJqoSFLkmVsNAlqRIWuiRVwkKXpEpY6JJUCQtdkiphoUtSJSx0SaqEhS5JlbDQJakS\nFrokVcJCl6RKWOiSVAkLXZIqYaFLUiUsdEmqhIUuSZWw0CWpEha6JFXCQpekSljoklQJC12SKmGh\nS1IlLHRJqoSFLkmVsNAlqRIWuiRVwkKXpEqMznZhROwHXAs8BXgM8F7g34C1wDhwF7AqM3dGxCXA\nqcB24ILMvGPhYkuSppprhH4mcH9mHgf8PvAh4HLgonbdCLAyIo4ClgPHAKcDVyxcZEnSdOYq9E8D\nF7fLIzSj76OBW9t164ATgWOB9Zk5npl3A6MRMbYAeSVJM5h1yiUzHwKIiKXA9cBFwGWZOd5eZStw\nMHAQcP+km06s3zzb9pctW8Lo6OL5JZ9ibGxpJ9vpWqm5ZlNi5j4y+Th0p8TcNWaatdABIuLJwA3A\nhzPzExHx/kkXLwUeAB5sl6eun9WWLdt2L+0MxsaWsnnz1k621aVSc82lxMx7O1OJv7sSMw2qxNzD\nnGmm4p91yiUifh1YD7wtM69tV38zIla0y6cAG4CNwMkRsSgiDgcWZeZ9AyWTJHVirhH6O4BlwMUR\nMTGX/ibgbyJif2ATcH1m7oiIDcBtNG8SqxYqsCRpenPNob+JpsCnWj7NddcAazpJJUnabR5YJEmV\nsNAlqRIWuiRVwkKXpEpY6JJUCQtdkiphoUtSJSx0SaqEhS5JlbDQJakSFrokVcJCl6RKWOiSVAkL\nXZIqYaFLUiUsdEmqhIUuSZWw0CWpEha6JFXCQpekSljoklQJC12SKmGhS1IlLHRJqoSFLkmVsNAl\nqRKjfQeQ9rbzLr25s21du/qEzrYl7SlH6JJUCUfoUgH8q0FdcIQuSZWw0CWpEha6JFXCQpekSljo\nklQJC12SKmGhS1IlLHRJqoSFLkmVsNAlqRIDHfofEccAf5mZKyLiCGAtMA7cBazKzJ0RcQlwKrAd\nuCAz71igzJKkacw5Qo+ItwLXAAe0qy4HLsrM44ARYGVEHAUsB44BTgeuWJi4kqSZDDLl8h/ASyb9\nfDRwa7u8DjgROBZYn5njmXk3MBoRY50mlSTNas4pl8z8TEQ8ZdKqkcwcb5e3AgcDBwH3T7rOxPrN\ns2172bIljI4u3q3AMxkbW9rJdrpWaq7ZlJi5xExQZi4zDabGTPM5fe7OSctLgQeAB9vlqetntWXL\ntnnc/a7GxpayefPWTrbVpVJzzaXEzCVmgjJzmWkww5xppuKfz14u34yIFe3yKcAGYCNwckQsiojD\ngUWZed88ti1Jmqf5jNAvBK6OiP2BTcD1mbkjIjYAt9G8SazqMKMkaQADFXpm/gB4drv8PZo9WqZe\nZw2wprtokqTd4YFFklQJC12SKmGhS1IlLHRJqoSFLkmVsNAlqRIWuiRVwkKXpEpY6JJUCQtdkiph\noUtSJSx0SaqEhS5JlZjP6XP3qvMuvbmzbV27+oTOtiVJpXGELkmVsNAlqRIWuiRVwkKXpEpY6JJU\nCQtdkiphoUtSJSx0SaqEhS5JlbDQJakSxR/6XyJPRyCpRI7QJakSFrokVcJCl6RKWOiSVAkLXZIq\nYaFLUiUsdEmqhIUuSZWw0CWpEha6JFXCQpekSljoklQJC12SKtHp2RYjYhHwYeAZwC+B8zPz+13e\nhyRpel2P0P8IOCAznwOsBj7Y8fYlSTPoutCPBb4AkJn/Ajyr4+1LkmYwMj4+3tnGIuIa4DOZua79\n+W7gqZm5vbM7kSRNq+sR+oPA0snbt8wlae/outA3Ai8CiIhnA3d2vH1J0gy6/k7RG4CTIuJrwAhw\nbsfblyTNoNM5dElSfzywSJIqYaFLUiUsdEmqhIUuSZWw0KUZRMRj+s4g7Y6ud1tccO3+7VcAPwdW\nZ+ZX2/U3ZOZpPWXaf8qq9cBJwEhmPtxDJAAi4vHAX9CckuGxwA9pjhV4b2Y+1Feu0kTEi4EPAY8A\n78zMT7YXrQNO6C1YYUp87bX3fyhwMXAv8E/AZ4HtwLmZeVtPmXrphKErdJoTfr0C2A+4LiJWZ+Z6\n4HE9ZvoJ8AtgG83+978BfA8YB57aY66raYrqDcBK4EnAfwIfAV7eR6CIuAWYOvIdAcYz87k9RAJ4\nJ/BMmr9YPx0RB2Tmx9pcvYiIj890/5l5xl6OM6HE1x7AdcAngcOBLwHHAz8DPg4s7ylTL50wjIX+\nSGZ+DyAiXgR8KSLOoHmg+vJs4DLg7Zl5Z0TckpnP7zHPhEMz8yvt8icjYn1mvjAiLuwx02qaN5rT\naEZRJXg4M7cARMRK4Ob2PER9PqeuB94H/FmPGaYq8bUHcGD7BkxErMjMbJd39pipl04YxkJ/MCLe\nCFyVmfe2T6hPseuob6/JzO9GxCuAv4uIm+j/CT5ha0Ssppk6+EPgnojoa8QCQGbeHhHXAU/PzBv6\nzDLJDyLicuDizNwaES8BvkiPI8/MvKH9XT0hMz/dV44pinvttbZExEXA+zLzBQARcSbNCLkXfXXC\nMH4oeiZwCO2TKDPvBF4KfKfPUJm5NTNfARxBM7VRgjOBQ2lGeo8B3ggcCLyqz1CZ+YGCyhzgPJrn\nzzhAZv4QeD5NWfUmMy8oqMyh0NcecAawNTMnl+aTgLN7ygP00wlDeeh/RIzRzJMdDDwA3JaZPzLT\nrtpcy4GDKCiX5lbic6rETFBmrj4yDV2hR8T5wGuArwJbaU7XezxwTWZeaaZdcr26zfVQm+s44CM9\nPlZHznTZxPzs3lZopuKeUyVmmiVX38/zXh6rYZxDPxd4XmY+MrGi3UVoI9DXk6rETNDkOrawXNfS\nfMr/XR69F8c4/e0iWGKmEp9TJWaCMnP1kmkYC30/mn2qH5m0bgn9fhBZYiYoM9cLgVuBszLzv3vM\nMVmJmUr83ZWYCcrM1UumYSz09wDfiIh/B35KMzd8BPBmM+2iuFyZuS0iXkezz3AR5VliJgr83RWa\nCcrM1UumoZtDB4iIUeBpNA/ST4Hv9v1VdyVmgnJzaW5TfncPApv6/t2VmAnKzNVHpqEr9Ig4AHgt\n8GOa+ajrgB3An08cUGCmcnOZaX4i4hM9HiE6rRIzQZm59lamYZxyWQtsAn4XeC/NC/EhmkPcTzLT\no6ylvFxmGkB7pOrE63MEOCQifkRzioQnmqnsXH1lGsYDiw7LzHfT7BL0y8z8SmbeTr//LyVmKjWX\nmQZzFnAHcHRmHgZ8LTMP67M4C81Uaq5eMvVdOPPxSES8MjN3As+A5vwN9Pv/UmImKDOXmQaQmbcC\nr6c5dHw5/e9JUmQmKDNXX5n6Lpz5OBN4FsCkDxj+GHhdb4nKzARl5jLTgDLzHuBlNPkO6zPLhBIz\nQZm5+sg0dB+KSvuiiDis70PZpyoxE5SZa29lstAlqRJDt5dLRHwHePyU1RNfkNDXJ9rFZYIyc5lp\nMGYaXIm5+so0dIUOvAT4B+D4zPx532FaJWaCMnOZaTBmGlyJuXrJNHQfimbm94G/pjlfdRFKzARl\n5jLTYMw0uBJz9ZXJOXRJqsQwTrlMfO/jifzqxPEbgOvz0d9Yss9nKjWXmcy0L+TqI9PQFXpEXEEz\nVbSOX504/hTgZOB8M5Wdy0xm2hdy9ZZpfHx8qP4deeSRt86wfqOZys9lJjPtC7n6yjR0H4oCiyLi\nuMkrIuJ4Hn0i+b2txExQZi4zDcZMgysxVy+Zhm7KBTgHuDwiPkGzX+dO4JvAG8y0i3MoL5eZzNS1\ncygvVy+ZhnGE/tvAM4GHgbdk5uGZuZJmFyEzPVqJucxkpq6VmKuXTMNY6O+kOSPe7wGviYiz2/Uj\nM99kwZWYCcrMZabBmGlwJebqJdMwTrk8nJkPwP/vFnRzezL5PnebKjETlJnLTGbqWom5esk0jCP0\nH0TE5RFxYGZupTnE9grgt8w0FLnMZKZ9IVcvmYax0M8DvkP7TpeZP6Q5vPZTZtpFibnMZKaulZir\nl0we+i9JlRjGEbokaRoWuiRVwkKXpEpY6BpKEfHuqYdWL8RtuhIRt0xa9oMrLQgLXcNqObB4L9ym\nKyt6ul/tQ9zLRcWLiCcBHwcOpDknxk3AW4F7gdOAQ4D3AUuAxwFvzswbI2ItcChwBHApzX7A9wKn\nZeadM9zXWuBnwFHttt4BnEVz1N+NmXlhRCwC/gp4Ac1uaddl5l9GxIr2+tuApwF3AmcAl9Gcw+OO\nzDymHaFfBTynvduXtt9wI+0RR+gaBn8K3JSZzwLeRVOYXwfOb4v5De3yUTTnmn7PpNven5lPy8yP\nTbnNbJ6Ymc+heRP4KPA6mvNyvDoiDm5/fjLwdJpDu18aEae2t30u8HqaQj8cODkz3wiQmcdMuo8v\nZ+YzgC8Br93tR0SahoWuYfBl4C3tmesOBT405fIzgd+JiIuBC4Ffm3TZ7fO4v3Xtf/8LuCszf9Ie\n7fe/wDLgBGBtZu7IzG00fz28oL3NXZl5T2buBDbR/PUwnRvb//4ru347vDQvFrqKl5kbac5e90Xg\n5cDnp1xlA81I+Rs0Uy+TT4A0n29cf3jS8vZpLp/6uhnhV+dF+sWk9ePMcDKmzNw+13Wk3WWhq3gR\n8X7grHba5PU089vbgdGIOAQ4kmYqZh2wkpk/+NxONyekuxk4OyIWR8QS4JXALXPcZkdEDOPJ8DRE\nLHQNg7+lmaf+FnAD8CrgC8CVNCc7uoZm6mITzXc3LomIA6fZzheAKyPiuXuY5yrgHuDbNF9a8I+Z\necMct/kc8O2IOGAP71uakXu5SFIl/BNQ+5yI+ABw0jQXfT0ze/v2emlPOUKXpEo4hy5JlbDQJakS\nFrokVcJCl6RKWOiSVIn/A4M705piKgKKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2823c8328d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "fnf_alice = pd.DataFrame(index=train_df.index)\n",
    "fnf_alice['start_month'] = train_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "fnf_alice['target'] = train_df['target']\n",
    "\n",
    "fnf_alice[fnf_alice['target'] == 1].groupby('start_month')['start_month'].count().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Таким образом, у нас есть иллюстрация и соображения насчет полезности нового признака, добавим его в обучающую выборку и проверим качество новой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.750835486018\n"
     ]
    }
   ],
   "source": [
    "# добавим новый признак в разреженную матрицу\n",
    "tmp = full_new_feat[['start_month']].as_matrix()\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
    "\n",
    "# считаем метрику на валидационной выборке\n",
    "print(get_auc_lr_valid(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Качество модели значительно ухудшилось. Мы добавили признак, который определенно казался нам полезным, но его использование только ухудшило модель. Почему так произошло?\n",
    "\n",
    "### Лирическое отступление 2: надо ли масштабировать признаки?\n",
    "\n",
    "Здесь мы приведем интуитивное рассуждение (строгое математическое обоснование того или иного аспекта в линейных моделях вы без труда найдете в сети). Рассмотрим признаки внимательнее: те из них, которые соответствуют количеству посещений определенного сайта за сессию, изменяются от 0 до 10. Признак `start_month` имеет совсем другую шкалу: от 201301 до 201412, это значит вклад этой переменной значительно больше остальных. Казалось бы, проблемы можно избежать, если поставить этому признаку меньший вес в линейной комбинации признаков, но в нашем случае используется логистическая регрессия с регуляризацией (по умолчанию этот параметр `C=1`), которая тем сильнее штрафует модель, чем ее веса больше.  Поэтому при использовании линейных методов с регуляризацией рекомендуется приводить признаки к одному масштабу (больше о регуляризации вы можете почитать, например, [здесь](https://habrahabr.ru/company/ods/blog/322076/)). \n",
    "\n",
    "Один из способов сделать это -- стандартизация: для каждого наблюдения надо отнять среднее по признаку и эту разность разделить на среднеквадратическое отклонение: \n",
    "\n",
    "$$ x^{*}_{i} = \\dfrac{x_{i} - \\mu_x}{\\sigma_x}$$\n",
    "\n",
    "Можно дать следующие практические советы:\n",
    "- рекомендуется масштабировать признаки, если они находятся в существенно разных шкалах или разных единицах измерения (например, население страны указано в единицах, а ВНП страны в триллионах);\n",
    "- масштабируйте признаки, если у вас нет оснований/экспертного мнения придавать больший вес каким-либо из них;\n",
    "- масштабирование может быть лишним, если диапазоны некоторых ваших признаков отличаются друг от друга, но при этом находятся в одной системе единиц (например, доли людей средних лет и старше 80 среди всего населения);\n",
    "- если вы хотите получить интерпретируемую модель, то постройте модель без регуляризации и масштабирования (скорее всего, ее качество окажется хуже);\n",
    "- бинарные переменные (принимают только значения 0 или 1) обычно оставляют без преобразования, (но)\n",
    "- если качество модели имеет решающее значение, попробуйте разные варианты и выберите тот, где качество выше.\n",
    "\n",
    "Возвращаяся к `start_month`, масштабируем новый признак и снова обучим модель. В этот раз качество возросло:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919698615157\n"
     ]
    }
   ],
   "source": [
    "# добавим новый стандартизированный признак в разреженную матрицу\n",
    "tmp = StandardScaler().fit_transform(full_new_feat[['start_month']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
    "\n",
    "# считаем метрику на валидационной выборке\n",
    "print(get_auc_lr_valid(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Задание 7: Добавьте в обучающую выборку признак n_unique_sites , количество уникальных сайтов в сессии, и посчитайте, как изменилось качество на отложенной выборке?\n",
    "\n",
    "- уменьшилось, новый признак лучше не масштабировать\n",
    "- не изменилось\n",
    "- уменьшилось, новый признак надо масштабировать\n",
    "- я в ступоре и не знаю, надо ли мастшабировать новый признак, а попробовать оба варианта и выбрать лучший не хватает смелости\n",
    "\n",
    "*Подсказки: воспользуйтесь функцией nunique() из Pandas. Не забудьте включить в выборку start_month. Будете ли вы мастшабировать новый признак? Почему?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_month</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242171</th>\n",
       "      <td>201301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57157</th>\n",
       "      <td>201301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240201</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210686</th>\n",
       "      <td>201301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98804</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113494</th>\n",
       "      <td>201301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223837</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145475</th>\n",
       "      <td>201301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186633</th>\n",
       "      <td>201301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45193</th>\n",
       "      <td>201301</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102930</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15789</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205868</th>\n",
       "      <td>201301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21102</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193454</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252924</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12713</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182016</th>\n",
       "      <td>201301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55750</th>\n",
       "      <td>201301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237109</th>\n",
       "      <td>201301</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120126</th>\n",
       "      <td>201301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140105</th>\n",
       "      <td>201301</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129357</th>\n",
       "      <td>201301</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136699</th>\n",
       "      <td>201301</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113189</th>\n",
       "      <td>201301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82768</th>\n",
       "      <td>201405</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82769</th>\n",
       "      <td>201410</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82770</th>\n",
       "      <td>201405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82771</th>\n",
       "      <td>201411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82772</th>\n",
       "      <td>201406</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82773</th>\n",
       "      <td>201406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82774</th>\n",
       "      <td>201410</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82775</th>\n",
       "      <td>201407</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82776</th>\n",
       "      <td>201405</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82777</th>\n",
       "      <td>201405</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82778</th>\n",
       "      <td>201406</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82779</th>\n",
       "      <td>201405</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82780</th>\n",
       "      <td>201407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82781</th>\n",
       "      <td>201407</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82782</th>\n",
       "      <td>201408</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82783</th>\n",
       "      <td>201405</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82784</th>\n",
       "      <td>201405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82785</th>\n",
       "      <td>201406</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82786</th>\n",
       "      <td>201407</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82787</th>\n",
       "      <td>201411</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82788</th>\n",
       "      <td>201412</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82789</th>\n",
       "      <td>201408</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82790</th>\n",
       "      <td>201410</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82791</th>\n",
       "      <td>201405</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82792</th>\n",
       "      <td>201405</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82793</th>\n",
       "      <td>201410</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82794</th>\n",
       "      <td>201405</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82795</th>\n",
       "      <td>201405</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82796</th>\n",
       "      <td>201405</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82797</th>\n",
       "      <td>201411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_month  nunique\n",
       "session_id                      \n",
       "21669            201301        3\n",
       "54843            201301        3\n",
       "77292            201301        6\n",
       "114021           201301        5\n",
       "146670           201301        6\n",
       "242171           201301        5\n",
       "57157            201301        5\n",
       "240201           201301        6\n",
       "210686           201301        5\n",
       "98804            201301        8\n",
       "113494           201301        4\n",
       "223837           201301        8\n",
       "145475           201301        5\n",
       "186633           201301        5\n",
       "45193            201301       10\n",
       "102930           201301        8\n",
       "15789            201301        8\n",
       "205868           201301        4\n",
       "21102            201301        6\n",
       "193454           201301        6\n",
       "252924           201301        6\n",
       "12713            201301        8\n",
       "182016           201301        8\n",
       "55750            201301        3\n",
       "237109           201301        7\n",
       "120126           201301        4\n",
       "140105           201301       10\n",
       "129357           201301        9\n",
       "136699           201301        4\n",
       "113189           201301        6\n",
       "...                 ...      ...\n",
       "82768            201405        6\n",
       "82769            201410        5\n",
       "82770            201405        2\n",
       "82771            201411        1\n",
       "82772            201406        8\n",
       "82773            201406        6\n",
       "82774            201410        9\n",
       "82775            201407        7\n",
       "82776            201405        7\n",
       "82777            201405        7\n",
       "82778            201406        7\n",
       "82779            201405        3\n",
       "82780            201407        5\n",
       "82781            201407        7\n",
       "82782            201408        7\n",
       "82783            201405        6\n",
       "82784            201405        2\n",
       "82785            201406        7\n",
       "82786            201407        3\n",
       "82787            201411        5\n",
       "82788            201412        5\n",
       "82789            201408        7\n",
       "82790            201410        9\n",
       "82791            201405        4\n",
       "82792            201405        8\n",
       "82793            201410        4\n",
       "82794            201405        6\n",
       "82795            201405       10\n",
       "82796            201405        7\n",
       "82797            201411        2\n",
       "\n",
       "[336358 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_new_feat['nunique'] = full_df[sites].apply(pd.Series.nunique, axis=1)\n",
    "full_new_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91569176944\n"
     ]
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "#full_new_feat['n_unique_sites'] = \n",
    "\n",
    "tmp = StandardScaler().fit_transform(full_new_feat[['nunique']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
    "\n",
    "print(get_auc_lr_valid(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Итак, новый признак немного ухудшил качество, поэтому мы не будем его использовать. Тем не менее, не спешите выкидывать признаки, которые не сработали. Они могут пригодится для комбинации новых признаков (например, когда новый признак является отношением или произведением двух других).\n",
    "\n",
    "##### Задание 8. Добавьте два новых признака: start_hour и morning. Посчитайте метрику, какие из признаков дали прирост?\n",
    "\n",
    "Признак `start_hour` это час в который началась сессия (от 0 до 23), а бинарный признак `morning` равен 1, если сессия началась утром и 0, если сессия началась позже (будем считать, что утро это если `start_hour равен` 11 или меньше).\n",
    "\n",
    "Будете ли вы масштабировать новые признаки? Сделайте предположения и проверьте их на практике.\n",
    "\n",
    "- ни один из признаков не дал прирост ;(\n",
    "- `start_hour` дал прирост, а `morning` нет\n",
    "- `morning` дал прирост, а `start_hour` почему-то нет\n",
    "- оба признака дали прирост\n",
    "\n",
    "*Подсказка: найдите в [справке](http://pandas.pydata.org/pandas-docs/stable/api.html) подходящие функции для работы с временными данными. Не забудьте включить признак `start_month`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947295090431\n"
     ]
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "full_new_feat['start_hour'] = full_df['time1'].apply(lambda ts: ts.hour)\n",
    "full_new_feat['morning'] = full_new_feat['start_hour'].apply(lambda h: 0 if h > 11 else 1)\n",
    "\n",
    "#tmp = StandardScaler().fit_transform(full_new_feat[['morning']])\n",
    "#tmp = full_new_feat[['morning']].values\n",
    "#X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], tmp[:idx_split,:]]))\n",
    "\n",
    "print(get_auc_lr_valid(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Подбор коэффицициента регуляризации\n",
    "\n",
    "Итак, мы ввели признаки, которые улучшают качество нашей модели по сравнению с первым бейслайном. Можем ли мы добиться большего значения метрики? После того, как мы сформировали обучающую и тестовую выборки, почти всегда имеет смысл подобрать оптимальные гиперпараметры — характеристики модели, которые не изменяются во время обучения. Например, на 3 неделе вы проходили решающие деревья, глубина дерева это гиперпараметр, а признак, по которому происходит ветвление и его значение — нет. В используемой нами логистической регрессии веса каждого признака изменяются, и во время обучения ищутся их оптимальные значения, а коэффициент регуляризации остается постоянным. Это тот гиперпараметр, который мы сейчас будем оптимизировать.\n",
    "\n",
    "Посчитаем качество на отложенной выборке с коэффициентом регуляризации, который по умолчанию  равен 1 (`C=1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959150251318\n"
     ]
    }
   ],
   "source": [
    "# формируем обучающую выборку\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', 'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "\n",
    "# зафиксируем качество с параметрами по умолчанию\n",
    "score_C_1 = get_auc_lr_valid(X_train, y_train)\n",
    "print(score_C_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Постараемся побить этот результат за счет оптимизации коэффициента регуляризации. Возьмем набор возможных значений C и для каждого из них посчитаем значение метрики на отложенной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  9.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# набор возможных значений С\n",
    "Cs = np.logspace(-3, 1, 10)\n",
    "\n",
    "scores = []\n",
    "    \n",
    "for C in Cs:\n",
    "    scores.append(get_auc_lr_valid(X_train, y_train, C=C))\n",
    "\n",
    "\n",
    "\n",
    "# установите и подключите этот модуль для отслеживания числа выполненных итераций \n",
    "\n",
    "from tqdm import tqdm\n",
    "for C in tqdm(Cs):\n",
    "     scores.append(get_auc_lr_valid(X_train, y_train, C=C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Построим график зависимости метрики от значения коэффициента регуляризации. Значение метрики с параметром C по умолчанию отображено горизонтальным пунктиром:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-4dc1912f4900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ro-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC-ROC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Подбор коэффициента регуляризации'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Python\\3.5\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3317\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Python\\3.5\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Python\\3.5\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Python\\3.5\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Python\\3.5\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Python\\3.5\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (20,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD7CAYAAACPDORaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2823f485438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Cs, scores, 'ro-')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.title('Подбор коэффициента регуляризации')\n",
    "# горизонтальная линия -- качество модели с коэффициентом по умолчанию\n",
    "plt.axhline(y=score_C_1, linewidth=.5, color = 'b', linestyle='dashed') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Задание 9:  при каком коэффициенте регуляризации C модель показывает наивысшее качество?\n",
    "\n",
    "- 0.17\n",
    "- 0.46\n",
    "- 1.29\n",
    "- 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96121402028414227,\n",
       " 0.96033543529508369,\n",
       " 0.95867246411991747,\n",
       " 0.95626797929075558]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код здесь\n",
    "Cs = [0.17, 0.46, 1.29, 3.14]\n",
    "\n",
    "\n",
    "scores = []\n",
    "    \n",
    "for C in Cs:\n",
    "    scores.append(get_auc_lr_valid(X_train, y_train, C=C))\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "И последнее в этой домашней работе: обучите модель с найденным оптимальным значением коэффициента регуляризации (не округляйте до двух знаков как в последнем задании). Если вы все сделали правильно и загрузите это решение, то повторите второй бейслайн — 0.93474 на паблик лидерборде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# подготовим данные для обучения и теста\n",
    "tmp_scaled = StandardScaler().fit_transform(full_new_feat[['start_month', 'start_hour', 'morning']])\n",
    "X_train = csr_matrix(hstack([full_sites_sparse[:idx_split,:], \n",
    "                             tmp_scaled[:idx_split,:]]))\n",
    "X_test = csr_matrix(hstack([full_sites_sparse[idx_split:,:], \n",
    "                            tmp_scaled[idx_split:,:]]))\n",
    "\n",
    "# обучим модель на всей выборке с оптимальным коэффициентом регуляризации\n",
    "lr = LogisticRegression(C=C, random_state=17).fit(X_train, y_train)\n",
    "\n",
    "# сделаем прогноз для тестовой выборки\n",
    "y_test = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# запишем его в файл, готовый для сабмита\n",
    "write_to_submission_file(y_test, 'baseline_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Заключение\n",
    "\n",
    "В этой домашней работе вы научились пользоваться разреженными матрицами и обучать модели логистической регрессии, создали несколько признаков и отобрали лучшие из них, узнали, зачем надо масштабировать признаки и как подбирать гиперпараметры. Вот напоследок несколько идей для новых признаков: подумайте, что нового вы можете придумать по образу и подобию уже имеющихся признаков, попробуйте умножение или деление двух из них, подкрепите свои догадки графиками, постарайтесь извлечь полезную информацию из временных данных (time1 ... time10), не стесняйтесь преобразовать уже имеющийся признак (например, прологарифмировать). Мы предлагаем вам пробовать новые идеи и модели на протяжении всего курса, участвовать в соревновании – это весело!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
